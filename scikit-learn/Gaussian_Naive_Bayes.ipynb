{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we have to classify messages as spam or not spam using the text in the messages. An Approcah we could follow is described below:\n",
    "\n",
    "1. find the probabilities of any message being spam P(S) = total spam messages/ total messages\n",
    "2. find the probabilities of any message being a normal message P(N) = total normal messages/ total messages\n",
    "3. find out the frequecies of different words in spam and non spam messages and create histograms\n",
    "    Eg: P(Dear | N) = total occurances of the word Dear in normal messages/ total no of words in normal messages\n",
    "        P(Friend | N) = 0.29\n",
    "        P(Lunch | N) = 0.17\n",
    "        P(Money | N) = 0.06\n",
    "   similarly,\n",
    "        P(Dear | S) = total occurances of the word Dear in normal messages/ total no of words in normal messages = 0.29\n",
    "        P(Friend | S) = 0.14\n",
    "        P(Lunch | S) = 0.00\n",
    "        P(Money | S) = 0.57\n",
    "4. Now once we get a new message we can look at the words in the message and calculate probabilities that the message could be a spam or not\n",
    "    Eg:  If we get the text \"Dear Friend\"\n",
    "        P(Dear | N)*P(Friend | N)*P(N) = 0.09  proportional to P(N | Dear Friend)\n",
    "        P(Dear | S)*P(Friend | S)*P(S) = 0.01  proportional to P(S | Dear Friend)\n",
    "5. As we can see the probability that the message is N given \"Dear Friend\" as text is more we can classify it as normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with the above approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assume we are tasked to classify the message \"Lunch Money Money Money\"\n",
    "- in the above example:\n",
    "        P(N | Lunch Money Money Money)  proportional to P(Lunch | N)*P(Money | N)^3*P(N)= 0.0002\n",
    "        P(S | Lunch Money Money Money)  proportional to P(Lunch | S)*P(Money | S)^3*P(S)= 0\n",
    "- the second value is 0 because the value of P(Lunch | S) = 0 ie. the word \"Lunch\" never appeared in the messages we know are spam\n",
    "- In such a scenario no matter how many times \"Money\" appears in our message the final result will always be more for normal case and we would classify it as normal message despite it being obviously spam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Solution to the zero probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Whenever we have a case where we are getting zero probability we can add a value alpha (usualy 1) to all the individuals words while calculating the probailities of each word given spam or normal\n",
    "        Eg: P(Lunch | S) = (no of time \"Lunch\" appeared in spam messages + 1) / (total words in spam messages + 1)\n",
    "- By adding this value our initial probabilities wont be affected as they are dependant on the number of spam and normal messages but the internal word probabilities change\n",
    "- By doing this for above example we end up with:\n",
    "        P(Lunch | N)*P(Money | N)^3*P(N)= 0.00002\n",
    "        P(Lunch | S)*P(Money | S)^3*P(S)= 0.00213\n",
    "- Thus we would be able to classify this as a Spam message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is Naive Bayes Naive?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Naive bayes method doesn't consider the relationship between the word in the above example\n",
    "        ie. P(Dear Friend | N) == P(Friend Dear | N)\n",
    "- Because the algorithm ignores obvious language related clues and just works with frequencies, it is termed as naive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As Naive bayes ignores the relation between the words it tends to have a high bias \n",
    "- But, in general it fits and is able to classify well so it has in general a low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gaussian Naive Bayes is named so because of the use of gaussian curves to determine the outcome\n",
    "- The core logic of Naive Bayes still applies in this case with a small addition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps are as follows:\n",
    "- Assume we havenumerical columns which are used to determine if a person likes a movie\n",
    "- We first find the mean and standard deviation for each of the column in 2 datasets. Those who love the specific movie and those who don't\n",
    "- These measurements will be helpful in plotting the normal distributions fitting the mean and sd for each column\n",
    "- Then we start with an initial prediction that a person loves the movie\n",
    "        Eg: If we have 8 people who love the movie and 8 people who don't then our initial prediction that a new person will love the movie is 0.5\n",
    "- NOTE: The initial guesses that a person will or will not love the movie are called Prior Probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NOTE: Likelihood is defined at the y axis value for a corresponding x axis value in the normal distribution for a column\n",
    "        Eg: If we are looking at pop corn consumption as a parameter and want to predict the likelihood that the person who eats 20 g of popcorn daily loves the movie. We simply plot the normal disribution for pop corn consumption for the people who love the movie and check the y axis value when x axis value is 20 g. this can be represented as L(popcorn=20 | loves the movie)\n",
    "        \n",
    "        \n",
    "- To predict if a new person would love the movie we can calculate the value of following:\n",
    "        prior probability of people loving the movie * L(popcorn = 20 | love)* L(candy=25 | love) ...\n",
    "- Similarly we can predict the value that a person wouldn't love the movie:\n",
    "        prior probability of people not loving the movie * L(popcorn = 20 | no love)* L(candy=25 | no love) ...\n",
    "- Sometimes likelihood values can get very small, so we can take a natural log() of above values to get the final results\n",
    "- Which ever result is greater there is more chances the person falls into that category\n",
    "        Eg: loves = -129  does no love = -58  Result: Person wouldn't love the movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source:\n",
    "- https://www.youtube.com/watch?v=O2L2Uv9pdDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 75 points : 4\n"
     ]
    }
   ],
   "source": [
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"% (X_test.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
