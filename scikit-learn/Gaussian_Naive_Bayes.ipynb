{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we have to classify messages as spam or not spam using the text in the messages. An Approcah we could follow is described below:\n",
    "\n",
    "1. find the probabilities of any message being spam P(S) = total spam messages/ total messages\n",
    "2. find the probabilities of any message being a normal message P(N) = total normal messages/ total messages\n",
    "3. find out the frequecies of different words in spam and non spam messages and create histograms\n",
    "    Eg: P(Dear | N) = total occurances of the word Dear in normal messages/ total no of words in normal messages\n",
    "        P(Friend | N) = 0.29\n",
    "        P(Lunch | N) = 0.17\n",
    "        P(Money | N) = 0.06\n",
    "   similarly,\n",
    "        P(Dear | S) = total occurances of the word Dear in normal messages/ total no of words in normal messages = 0.29\n",
    "        P(Friend | S) = 0.14\n",
    "        P(Lunch | S) = 0.00\n",
    "        P(Money | S) = 0.57\n",
    "4. Now once we get a new message we can look at the words in the message and calculate probabilities that the message could be a spam or not\n",
    "    Eg:  If we get the text \"Dear Friend\"\n",
    "        P(Dear | N)*P(Friend | N)*P(N) = 0.09  proportional to P(N | Dear Friend)\n",
    "        P(Dear | S)*P(Friend | S)*P(S) = 0.01  proportional to P(S | Dear Friend)\n",
    "5. As we can see the probability that the message is N given \"Dear Friend\" as text is more we can classify it as normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with the above approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assume we are tasked to classify the message \"Lunch Money Money Money\"\n",
    "- in the above example:\n",
    "        P(N | Lunch Money Money Money)  proportional to P(Lunch | N)*P(Money | N)^3*P(N)= 0.0002\n",
    "        P(S | Lunch Money Money Money)  proportional to P(Lunch | S)*P(Money | S)^3*P(S)= 0\n",
    "- the second value is 0 because the value of P(Lunch | S) = 0 ie. the word \"Lunch\" never appeared in the messages we know are spam\n",
    "- In such a scenario no matter how many times \"Money\" appears in our message the final result will always be more for normal case and we would classify it as normal message despite it being obviously spam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Solution to the zero probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Whenever we have a case where we are getting zero probability we can add a value alpha (usualy 1) to all the individuals words while calculating the probailities of each word given spam or normal\n",
    "        Eg: P(Lunch | S) = (no of time \"Lunch\" appeared in spam messages + 1) / (total words in spam messages + 1)\n",
    "- By adding this value our initial probabilities wont be affected as they are dependant on the number of spam and normal messages but the internal word probabilities change\n",
    "- By doing this for above example we end up with:\n",
    "        P(Lunch | N)*P(Money | N)^3*P(N)= 0.00002\n",
    "        P(Lunch | S)*P(Money | S)^3*P(S)= 0.00213\n",
    "- Thus we would be able to classify this as a Spam message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is Naive Bayes Naive?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Naive bayes method doesn't consider the relationship between the word in the above example\n",
    "        ie. P(Dear Friend | N) == P(Friend Dear | N)\n",
    "- Because the algorithm ignores obvious language related clues and just works with frequencies, it is termed as naive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As Naive bayes ignores the relation between the words it tends to have a high bias \n",
    "- But, in general it fits and is able to classify well so it has in general a low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source:\n",
    "- https://www.youtube.com/watch?v=O2L2Uv9pdDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
